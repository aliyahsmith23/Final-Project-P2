{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style= \"text-align= center;\"> blah blah blah <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math as math \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some imports we'll use through the notebook, collected here for simplicity\n",
    "\n",
    "# For parsing dates and being able to compare\n",
    "import datetime\n",
    "\n",
    "# For fetching remote data\n",
    "import urllib\n",
    "\n",
    "# Pandas dataframes and operations\n",
    "import pandas as pd\n",
    "\n",
    "# Numpy matrix and array operations\n",
    "import numpy as np\n",
    "\n",
    "# Sqlite is a simplistic database\n",
    "import sqlite3\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib\n",
    "\n",
    "#HAD ISSUES INSTALLING # Crawler for multiple web pages at once\n",
    "#import scrapy\n",
    "#from scrapy.crawler import CrawlerProcess\n",
    "# Can use dataframe.swifter.apply() instead of dataframe.apply()\n",
    "# to try to parallelize the computation!\n",
    "#import swifter\n",
    "# Approximate string matching, see \n",
    "#import py_stringsimjoin as ssj\n",
    "#import py_stringmatching as sm\n",
    "# import urllib and etree for download and parsing\n",
    "#from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', delimiter=',')\n",
    "# DELIMITER WHAT SEPERATES THE DATA (;)\n",
    "\n",
    "print(type(data))\n",
    "\n",
    "#Aliyah data defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_csv('CityState.csv', delimiter=',', engine='python', encoding='latin1')\n",
    "\n",
    "#Jay's data defined \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>displayName</th>\n",
       "      <th>cost-after-aid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Princeton</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Princeton University</td>\n",
       "      <td>16793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cambridge</td>\n",
       "      <td>MA</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>16338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>University of Chicago</td>\n",
       "      <td>27767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>Yale University</td>\n",
       "      <td>18385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>21041.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city state            displayName  cost-after-aid\n",
       "0     Princeton    NJ   Princeton University         16793.0\n",
       "1     Cambridge    MA     Harvard University         16338.0\n",
       "2       Chicago    IL  University of Chicago         27767.0\n",
       "3     New Haven    CT        Yale University         18385.0\n",
       "4      New York    NY    Columbia University         21041.0\n",
       "...         ...   ...                    ...             ...\n",
       "6995        NaN   NaN                    NaN             NaN\n",
       "6996        NaN   NaN                    NaN             NaN\n",
       "6997        NaN   NaN                    NaN             NaN\n",
       "6998        NaN   NaN                    NaN             NaN\n",
       "6999        NaN   NaN                    NaN             NaN\n",
       "\n",
       "[7000 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_list = ['city', 'state', 'displayName','cost-after-aid']\n",
    "row = list(range(7000))\n",
    "new_data = pd.DataFrame(data, index=row, columns=columns_list)\n",
    "new_data.head(7000)\n",
    "\n",
    "#Aliyah's data print desired columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State_ab</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chickasaw</td>\n",
       "      <td>AL</td>\n",
       "      <td>38773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Louisville</td>\n",
       "      <td>AL</td>\n",
       "      <td>37725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Columbiana</td>\n",
       "      <td>AL</td>\n",
       "      <td>54606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Satsuma</td>\n",
       "      <td>AL</td>\n",
       "      <td>63919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dauphin Island</td>\n",
       "      <td>AL</td>\n",
       "      <td>77948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>Pompano Beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>50778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>Dania Beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>69836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>Coral Springs</td>\n",
       "      <td>FL</td>\n",
       "      <td>150858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>Coral Springs</td>\n",
       "      <td>FL</td>\n",
       "      <td>119477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>Coconut Creek</td>\n",
       "      <td>FL</td>\n",
       "      <td>47168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                City State_ab    Mean\n",
       "0          Chickasaw       AL   38773\n",
       "1         Louisville       AL   37725\n",
       "2         Columbiana       AL   54606\n",
       "3            Satsuma       AL   63919\n",
       "4     Dauphin Island       AL   77948\n",
       "...              ...      ...     ...\n",
       "6995   Pompano Beach       FL   50778\n",
       "6996     Dania Beach       FL   69836\n",
       "6997   Coral Springs       FL  150858\n",
       "6998   Coral Springs       FL  119477\n",
       "6999   Coconut Creek       FL   47168\n",
       "\n",
       "[7000 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_list = ['City', 'State_ab', 'Mean']\n",
    "row = list(range(7000))\n",
    "new_data = pd.DataFrame(data_2, index=row, columns=columns_list)\n",
    "new_data.head(7000)\n",
    "\n",
    "#Jay's data print desired columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 City State_ab   Mean\n",
      "0           Chickasaw       AL  38773\n",
      "1          Louisville       AL  37725\n",
      "2          Columbiana       AL  54606\n",
      "3             Satsuma       AL  63919\n",
      "4      Dauphin Island       AL  77948\n",
      "...               ...      ...    ...\n",
      "32521        Guaynabo       PR  30649\n",
      "32522          Aguada       PR  15520\n",
      "32523          Aguada       PR  41933\n",
      "32524          Aguada       PR      0\n",
      "32525       Aguadilla       PR  28049\n",
      "\n",
      "[32526 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "jay_data = data_2[['City', 'State_ab', 'Mean']]\n",
    "print(jay_data)\n",
    "#Jay's data print desired columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            city state                       displayName  cost-after-aid\n",
      "0      Princeton    NJ              Princeton University         16793.0\n",
      "1      Cambridge    MA                Harvard University         16338.0\n",
      "2        Chicago    IL             University of Chicago         27767.0\n",
      "3      New Haven    CT                   Yale University         18385.0\n",
      "4       New York    NY               Columbia University         21041.0\n",
      "..           ...   ...                               ...             ...\n",
      "306      Cypress    CA  Trident University International             NaN\n",
      "307   Cincinnati    OH    Union Institute and University             NaN\n",
      "308      Phoenix    AZ             University of Phoenix             NaN\n",
      "309  Minneapolis    MN                 Walden University             NaN\n",
      "310   New Castle    DE             Wilmington University             NaN\n",
      "\n",
      "[311 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the name and born data in exec_df.  We do this via projection.  \n",
    "# Notice also (e.g. row 24) that special characters will cause issues.\n",
    "\n",
    "\n",
    "aliyah_data = data[['city', 'state', 'displayName','cost-after-aid']]\n",
    "print(aliyah_data)\n",
    "#Aliyah's data print desired columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           city state                      displayName  cost-after-aid\n",
      "0     Princeton    NJ             Princeton University         16793.0\n",
      "1     Cambridge    MA               Harvard University         16338.0\n",
      "2       Chicago    IL            University of Chicago         27767.0\n",
      "3     New Haven    CT                  Yale University         18385.0\n",
      "4      New York    NY              Columbia University         21041.0\n",
      "..          ...   ...                              ...             ...\n",
      "145   Corvallis    OR          Oregon State University         36636.0\n",
      "146   Rochester    NY          St. John Fisher College         28750.0\n",
      "147     Chicago    IL  University of Illinois--Chicago         39033.0\n",
      "148  University    MS        University of Mississippi         27943.0\n",
      "149  Richardson    TX      University of Texas--Dallas         37028.0\n",
      "\n",
      "[143 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(aliyah_data) \n",
    "aliyah_clean = df.dropna()\n",
    "print(aliyah_clean)\n",
    "#Aliyah data dropped all NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 City State_ab   Mean\n",
      "0           Chickasaw       AL  38773\n",
      "1          Louisville       AL  37725\n",
      "2          Columbiana       AL  54606\n",
      "3             Satsuma       AL  63919\n",
      "4      Dauphin Island       AL  77948\n",
      "...               ...      ...    ...\n",
      "32521        Guaynabo       PR  30649\n",
      "32522          Aguada       PR  15520\n",
      "32523          Aguada       PR  41933\n",
      "32524          Aguada       PR      0\n",
      "32525       Aguadilla       PR  28049\n",
      "\n",
      "[32526 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(jay_data) \n",
    "df_dropped = df.dropna()\n",
    "print(df_dropped)\n",
    "#Jay data dropped all NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 City State_ab   Mean\n",
      "0           Chickasaw       AL  38773\n",
      "1          Louisville       AL  37725\n",
      "2          Columbiana       AL  54606\n",
      "3             Satsuma       AL  63919\n",
      "4      Dauphin Island       AL  77948\n",
      "...               ...      ...    ...\n",
      "32520        Adjuntas       PR  23682\n",
      "32521        Guaynabo       PR  30649\n",
      "32522          Aguada       PR  15520\n",
      "32523          Aguada       PR  41933\n",
      "32525       Aguadilla       PR  28049\n",
      "\n",
      "[32211 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "jay_clean = df_dropped[df_dropped['Mean'] != 0]\n",
    "\n",
    "print(jay_clean)\n",
    "\n",
    "#Jay's data that dropped the 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           City State_ab   Mean       city state   \n",
      "0     Cleveland       AL  55127  Cleveland    OH  \\\n",
      "1     Cleveland       AL  56385  Cleveland    OH   \n",
      "2     Cleveland       GA  44684  Cleveland    OH   \n",
      "3     Cleveland       MS  34603  Cleveland    OH   \n",
      "4     Cleveland       MS  25632  Cleveland    OH   \n",
      "...         ...      ...    ...        ...   ...   \n",
      "7480  Milwaukee       WI  45808  Milwaukee    WI   \n",
      "7481  Milwaukee       WI  38857  Milwaukee    WI   \n",
      "7482  Milwaukee       WI  59171  Milwaukee    WI   \n",
      "7483  Milwaukee       WI  37089  Milwaukee    WI   \n",
      "7484  Milwaukee       WI  23988  Milwaukee    WI   \n",
      "\n",
      "                          displayName  cost-after-aid  \n",
      "0     Case Western Reserve University         35248.0  \n",
      "1     Case Western Reserve University         35248.0  \n",
      "2     Case Western Reserve University         35248.0  \n",
      "3     Case Western Reserve University         35248.0  \n",
      "4     Case Western Reserve University         35248.0  \n",
      "...                               ...             ...  \n",
      "7480             Marquette University         32894.0  \n",
      "7481             Marquette University         32894.0  \n",
      "7482             Marquette University         32894.0  \n",
      "7483             Marquette University         32894.0  \n",
      "7484             Marquette University         32894.0  \n",
      "\n",
      "[7485 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.merge(jay_clean, aliyah_clean, left_on='City', right_on='city')\n",
    "print(merged_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           City State_ab   Mean                      displayName   \n",
      "0     Cleveland       AL  55127  Case Western Reserve University  \\\n",
      "1     Cleveland       AL  56385  Case Western Reserve University   \n",
      "2     Cleveland       GA  44684  Case Western Reserve University   \n",
      "3     Cleveland       MS  34603  Case Western Reserve University   \n",
      "4     Cleveland       MS  25632  Case Western Reserve University   \n",
      "...         ...      ...    ...                              ...   \n",
      "7480  Milwaukee       WI  45808             Marquette University   \n",
      "7481  Milwaukee       WI  38857             Marquette University   \n",
      "7482  Milwaukee       WI  59171             Marquette University   \n",
      "7483  Milwaukee       WI  37089             Marquette University   \n",
      "7484  Milwaukee       WI  23988             Marquette University   \n",
      "\n",
      "      cost-after-aid  \n",
      "0            35248.0  \n",
      "1            35248.0  \n",
      "2            35248.0  \n",
      "3            35248.0  \n",
      "4            35248.0  \n",
      "...              ...  \n",
      "7480         32894.0  \n",
      "7481         32894.0  \n",
      "7482         32894.0  \n",
      "7483         32894.0  \n",
      "7484         32894.0  \n",
      "\n",
      "[7485 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you have a large DataFrame called \"data\" with columns A, B, C, D\n",
    "\n",
    "# Specify the column(s) to be deleted\n",
    "columns_to_delete = ['state','city']\n",
    "\n",
    "# Create a new DataFrame by selecting the columns you want to keep\n",
    "data = merged_data.drop(columns_to_delete, axis=1)\n",
    "\n",
    "# The resulting DataFrame will have columns A, B\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   State         City\n",
      "0     31     New York\n",
      "1      4  Los Angeles\n",
      "2     40       Dallas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'State': ['NY', 'CA', 'TX'], 'City': ['New York', 'Los Angeles', 'Dallas']})\n",
    "\n",
    "state_abbreviations = {'AL':1, 'AR':2, 'AZ':3, 'CA':4, 'CO':5, 'CT':6, 'DC':7, 'DE':8, 'FL':9, 'GA':10, 'IA':11, 'ID':12, 'IL':13, 'IN':14, 'KS':15, 'KY':16, 'LA':17, 'MA':18, 'MD':19, 'ME':20, 'MI':21, 'MN':22, 'MO':23, 'MS':24, 'MT':25, 'NC':26, 'ND':27, 'NE':28, 'NH':29, 'NJ':30, 'NY':31, 'OH':32, 'OK':33, 'OR':34, 'PA':35, 'RI':36, 'SC':37, 'SD':38, 'TN':39, 'TX':40, 'UT':41, 'VA':42, 'VT':43, 'WA':44, 'WI':45, 'WV':46, 'WY':47}\n",
    "\n",
    "# Replace state abbreviations with their corresponding values\n",
    "data.replace({'State': state_abbreviations}, inplace=True)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [37425, 7485]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m y \u001b[39m=\u001b[39m merged_data\u001b[39m.\u001b[39miloc[:,\u001b[39m6\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      5\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m \u001b[39m# Create an instance of the LinearRegression model\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model \u001b[39m=\u001b[39m LinearRegression()\n",
      "File \u001b[1;32mc:\\Users\\bigsh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2556\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m   2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[0;32m   2564\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\bigsh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\bigsh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [37425, 7485]"
     ]
    }
   ],
   "source": [
    "X = merged_data.iloc[:,1:6].values.reshape(-1, 1)\n",
    "y = merged_data.iloc[:,6].values\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the LinearRegression model\n",
    "model = LinearRegression()\n",
    "\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = merged_data.shape[1]\n",
    "# print(size)\n",
    "# for index in range(0,size-1):\n",
    "#    print(np.unique(merged_data.iloc[:,index]))\n",
    "\n",
    "# city_numerical = {'Ames':1, 'Amherst':2, 'Ann Arbor':3,  }  \n",
    "# state_numerical = {}\n",
    "# merged_data.replace(city_numerical.keys,city_numerical.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "#mse = mean_squared_error(y_test, y_pred)\n",
    "#r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "#print(\"Mean Squared Error:\", mse)\n",
    "#print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# prediction of the the model \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m classification_results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(classification_results) \n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# prediction of the the model \n",
    "classification_results = model.predict(X_test)\n",
    "print(classification_results) \n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of the the model \n",
    "predicted_results = model.predict(X_test)\n",
    "print(predicted_results) \n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# #CARLOS\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# # print metrics\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# # Generate the classification report\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m# print(classification_report(classification_results_categorical, y_test, zero_division=0)) \u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[39mprint\u001b[39m(mean_squared_error(y_test, predicted_results))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# #CARLOS\n",
    "# # print metrics\n",
    "\n",
    "# # Convert continuous predictions to categorical\n",
    "# classification_results_categorical = np.round(classification_results).astype(int)\n",
    "\n",
    "# # Ensure the shape and data types match\n",
    "# classification_results_categorical = classification_results_categorical.flatten()\n",
    "# y_test = y_test.flatten()\n",
    "\n",
    "# # Generate the classification report\n",
    "# print(classification_report(classification_results_categorical, y_test, zero_division=0)) \n",
    "\n",
    "print(mean_squared_error(y_test, predicted_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[223], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#print confusion matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m confusion \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39;49mconfusion_matrix(X_test, classification_results)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(confusion)\n",
      "File \u001b[1;32mc:\\Users\\bigsh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfusion_matrix\u001b[39m(\n\u001b[0;32m    233\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    234\u001b[0m ):\n\u001b[0;32m    235\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \n\u001b[0;32m    237\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    319\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\bigsh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "#print confusion matrix\n",
    "confusion = metrics.confusion_matrix(X_test, predicted_results)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[224], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m      4\u001b[0m \u001b[39m# Compute the confusion matrix\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_true, y_pred)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Create a custom confusion matrix plot\u001b[39;00m\n\u001b[0;32m      8\u001b[0m plt\u001b[39m.\u001b[39mimshow(cm, cmap\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mcm\u001b[39m.\u001b[39mBlues)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data  # Input features\n",
    "y_true = iris.target\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Create a custom confusion matrix plot\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.xticks(ticks=np.arange(len(classes)), labels=classes)\n",
    "plt.yticks(ticks=np.arange(len(classes)), labels=classes)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
