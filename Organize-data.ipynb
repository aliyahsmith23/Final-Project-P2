{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style= \"text-align= center;\"> blah blah blah <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math as math \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some imports we'll use through the notebook, collected here for simplicity\n",
    "\n",
    "# For parsing dates and being able to compare\n",
    "import datetime\n",
    "\n",
    "# For fetching remote data\n",
    "import urllib\n",
    "\n",
    "# Pandas dataframes and operations\n",
    "import pandas as pd\n",
    "\n",
    "# Numpy matrix and array operations\n",
    "import numpy as np\n",
    "\n",
    "# Sqlite is a simplistic database\n",
    "import sqlite3\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib\n",
    "\n",
    "#HAD ISSUES INSTALLING # Crawler for multiple web pages at once\n",
    "#import scrapy\n",
    "#from scrapy.crawler import CrawlerProcess\n",
    "# Can use dataframe.swifter.apply() instead of dataframe.apply()\n",
    "# to try to parallelize the computation!\n",
    "#import swifter\n",
    "# Approximate string matching, see \n",
    "#import py_stringsimjoin as ssj\n",
    "#import py_stringmatching as sm\n",
    "# import urllib and etree for download and parsing\n",
    "#from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', delimiter=',')\n",
    "# DELIMITER WHAT SEPERATES THE DATA (;)\n",
    "\n",
    "print(type(data))\n",
    "\n",
    "#Aliyah data defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_csv('CityState.csv', delimiter=',', engine='python', encoding='latin1')\n",
    "\n",
    "#Jay's data defined \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>displayName</th>\n",
       "      <th>cost-after-aid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Princeton</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Princeton University</td>\n",
       "      <td>16793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cambridge</td>\n",
       "      <td>MA</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>16338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>University of Chicago</td>\n",
       "      <td>27767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>Yale University</td>\n",
       "      <td>18385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>21041.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city state            displayName  cost-after-aid\n",
       "0     Princeton    NJ   Princeton University         16793.0\n",
       "1     Cambridge    MA     Harvard University         16338.0\n",
       "2       Chicago    IL  University of Chicago         27767.0\n",
       "3     New Haven    CT        Yale University         18385.0\n",
       "4      New York    NY    Columbia University         21041.0\n",
       "...         ...   ...                    ...             ...\n",
       "6995        NaN   NaN                    NaN             NaN\n",
       "6996        NaN   NaN                    NaN             NaN\n",
       "6997        NaN   NaN                    NaN             NaN\n",
       "6998        NaN   NaN                    NaN             NaN\n",
       "6999        NaN   NaN                    NaN             NaN\n",
       "\n",
       "[7000 rows x 4 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_list = ['city', 'state', 'displayName','cost-after-aid']\n",
    "row = list(range(7000))\n",
    "new_data = pd.DataFrame(data, index=row, columns=columns_list)\n",
    "new_data.head(7000)\n",
    "\n",
    "#Aliyah's data print desired columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State_ab</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chickasaw</td>\n",
       "      <td>AL</td>\n",
       "      <td>38773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Louisville</td>\n",
       "      <td>AL</td>\n",
       "      <td>37725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Columbiana</td>\n",
       "      <td>AL</td>\n",
       "      <td>54606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Satsuma</td>\n",
       "      <td>AL</td>\n",
       "      <td>63919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dauphin Island</td>\n",
       "      <td>AL</td>\n",
       "      <td>77948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>Pompano Beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>50778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>Dania Beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>69836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>Coral Springs</td>\n",
       "      <td>FL</td>\n",
       "      <td>150858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>Coral Springs</td>\n",
       "      <td>FL</td>\n",
       "      <td>119477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>Coconut Creek</td>\n",
       "      <td>FL</td>\n",
       "      <td>47168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                City State_ab    Mean\n",
       "0          Chickasaw       AL   38773\n",
       "1         Louisville       AL   37725\n",
       "2         Columbiana       AL   54606\n",
       "3            Satsuma       AL   63919\n",
       "4     Dauphin Island       AL   77948\n",
       "...              ...      ...     ...\n",
       "6995   Pompano Beach       FL   50778\n",
       "6996     Dania Beach       FL   69836\n",
       "6997   Coral Springs       FL  150858\n",
       "6998   Coral Springs       FL  119477\n",
       "6999   Coconut Creek       FL   47168\n",
       "\n",
       "[7000 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_list = ['City', 'State_ab', 'Mean']\n",
    "row = list(range(7000))\n",
    "new_data = pd.DataFrame(data_2, index=row, columns=columns_list)\n",
    "new_data.head(7000)\n",
    "\n",
    "#Jay's data print desired columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 City State_ab   Mean\n",
      "0           Chickasaw       AL  38773\n",
      "1          Louisville       AL  37725\n",
      "2          Columbiana       AL  54606\n",
      "3             Satsuma       AL  63919\n",
      "4      Dauphin Island       AL  77948\n",
      "...               ...      ...    ...\n",
      "32521        Guaynabo       PR  30649\n",
      "32522          Aguada       PR  15520\n",
      "32523          Aguada       PR  41933\n",
      "32524          Aguada       PR      0\n",
      "32525       Aguadilla       PR  28049\n",
      "\n",
      "[32526 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "jay_data = data_2[['City', 'State_ab', 'Mean']]\n",
    "print(jay_data)\n",
    "#Jay's data print desired columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            city state                       displayName  cost-after-aid\n",
      "0      Princeton    NJ              Princeton University         16793.0\n",
      "1      Cambridge    MA                Harvard University         16338.0\n",
      "2        Chicago    IL             University of Chicago         27767.0\n",
      "3      New Haven    CT                   Yale University         18385.0\n",
      "4       New York    NY               Columbia University         21041.0\n",
      "..           ...   ...                               ...             ...\n",
      "306      Cypress    CA  Trident University International             NaN\n",
      "307   Cincinnati    OH    Union Institute and University             NaN\n",
      "308      Phoenix    AZ             University of Phoenix             NaN\n",
      "309  Minneapolis    MN                 Walden University             NaN\n",
      "310   New Castle    DE             Wilmington University             NaN\n",
      "\n",
      "[311 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the name and born data in exec_df.  We do this via projection.  \n",
    "# Notice also (e.g. row 24) that special characters will cause issues.\n",
    "\n",
    "\n",
    "aliyah_data = data[['city', 'state', 'displayName','cost-after-aid']]\n",
    "print(aliyah_data)\n",
    "#Aliyah's data print desired columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           city state                      displayName  cost-after-aid\n",
      "0     Princeton    NJ             Princeton University         16793.0\n",
      "1     Cambridge    MA               Harvard University         16338.0\n",
      "2       Chicago    IL            University of Chicago         27767.0\n",
      "3     New Haven    CT                  Yale University         18385.0\n",
      "4      New York    NY              Columbia University         21041.0\n",
      "..          ...   ...                              ...             ...\n",
      "145   Corvallis    OR          Oregon State University         36636.0\n",
      "146   Rochester    NY          St. John Fisher College         28750.0\n",
      "147     Chicago    IL  University of Illinois--Chicago         39033.0\n",
      "148  University    MS        University of Mississippi         27943.0\n",
      "149  Richardson    TX      University of Texas--Dallas         37028.0\n",
      "\n",
      "[143 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(aliyah_data) \n",
    "aliyah_clean = df.dropna()\n",
    "print(aliyah_clean)\n",
    "#Aliyah data dropped all NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 City State_ab   Mean\n",
      "0           Chickasaw       AL  38773\n",
      "1          Louisville       AL  37725\n",
      "2          Columbiana       AL  54606\n",
      "3             Satsuma       AL  63919\n",
      "4      Dauphin Island       AL  77948\n",
      "...               ...      ...    ...\n",
      "32521        Guaynabo       PR  30649\n",
      "32522          Aguada       PR  15520\n",
      "32523          Aguada       PR  41933\n",
      "32524          Aguada       PR      0\n",
      "32525       Aguadilla       PR  28049\n",
      "\n",
      "[32526 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(jay_data) \n",
    "df_dropped = df.dropna()\n",
    "print(df_dropped)\n",
    "#Jay data dropped all NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 City State_ab   Mean\n",
      "0           Chickasaw       AL  38773\n",
      "1          Louisville       AL  37725\n",
      "2          Columbiana       AL  54606\n",
      "3             Satsuma       AL  63919\n",
      "4      Dauphin Island       AL  77948\n",
      "...               ...      ...    ...\n",
      "32520        Adjuntas       PR  23682\n",
      "32521        Guaynabo       PR  30649\n",
      "32522          Aguada       PR  15520\n",
      "32523          Aguada       PR  41933\n",
      "32525       Aguadilla       PR  28049\n",
      "\n",
      "[32211 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "jay_clean = df_dropped[df_dropped['Mean'] != 0]\n",
    "\n",
    "print(jay_clean)\n",
    "\n",
    "#Jay's data that dropped the 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           City State_ab   Mean       city state   \n",
      "0     Cleveland       AL  55127  Cleveland    OH  \\\n",
      "1     Cleveland       AL  56385  Cleveland    OH   \n",
      "2     Cleveland       GA  44684  Cleveland    OH   \n",
      "3     Cleveland       MS  34603  Cleveland    OH   \n",
      "4     Cleveland       MS  25632  Cleveland    OH   \n",
      "...         ...      ...    ...        ...   ...   \n",
      "7480  Milwaukee       WI  45808  Milwaukee    WI   \n",
      "7481  Milwaukee       WI  38857  Milwaukee    WI   \n",
      "7482  Milwaukee       WI  59171  Milwaukee    WI   \n",
      "7483  Milwaukee       WI  37089  Milwaukee    WI   \n",
      "7484  Milwaukee       WI  23988  Milwaukee    WI   \n",
      "\n",
      "                          displayName  cost-after-aid  \n",
      "0     Case Western Reserve University         35248.0  \n",
      "1     Case Western Reserve University         35248.0  \n",
      "2     Case Western Reserve University         35248.0  \n",
      "3     Case Western Reserve University         35248.0  \n",
      "4     Case Western Reserve University         35248.0  \n",
      "...                               ...             ...  \n",
      "7480             Marquette University         32894.0  \n",
      "7481             Marquette University         32894.0  \n",
      "7482             Marquette University         32894.0  \n",
      "7483             Marquette University         32894.0  \n",
      "7484             Marquette University         32894.0  \n",
      "\n",
      "[7485 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.merge(jay_clean, aliyah_clean, left_on='City', right_on='city')\n",
    "print(merged_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           City State_ab   Mean                      displayName   \n",
      "0     Cleveland       AL  55127  Case Western Reserve University  \\\n",
      "1     Cleveland       AL  56385  Case Western Reserve University   \n",
      "2     Cleveland       GA  44684  Case Western Reserve University   \n",
      "3     Cleveland       MS  34603  Case Western Reserve University   \n",
      "4     Cleveland       MS  25632  Case Western Reserve University   \n",
      "...         ...      ...    ...                              ...   \n",
      "7480  Milwaukee       WI  45808             Marquette University   \n",
      "7481  Milwaukee       WI  38857             Marquette University   \n",
      "7482  Milwaukee       WI  59171             Marquette University   \n",
      "7483  Milwaukee       WI  37089             Marquette University   \n",
      "7484  Milwaukee       WI  23988             Marquette University   \n",
      "\n",
      "      cost-after-aid  \n",
      "0            35248.0  \n",
      "1            35248.0  \n",
      "2            35248.0  \n",
      "3            35248.0  \n",
      "4            35248.0  \n",
      "...              ...  \n",
      "7480         32894.0  \n",
      "7481         32894.0  \n",
      "7482         32894.0  \n",
      "7483         32894.0  \n",
      "7484         32894.0  \n",
      "\n",
      "[7485 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "columns_to_delete = ['state','city']\n",
    "\n",
    "# Create a new DataFrame by selecting the columns you want to keep\n",
    "data = merged_data.drop(columns_to_delete, axis=1)\n",
    "\n",
    "# The resulting DataFrame will have columns A, B\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           City  State_ab   Mean                      displayName   \n",
      "0     Cleveland         1  55127  Case Western Reserve University  \\\n",
      "1     Cleveland         1  56385  Case Western Reserve University   \n",
      "2     Cleveland        10  44684  Case Western Reserve University   \n",
      "3     Cleveland        24  34603  Case Western Reserve University   \n",
      "4     Cleveland        24  25632  Case Western Reserve University   \n",
      "...         ...       ...    ...                              ...   \n",
      "7480  Milwaukee        45  45808             Marquette University   \n",
      "7481  Milwaukee        45  38857             Marquette University   \n",
      "7482  Milwaukee        45  59171             Marquette University   \n",
      "7483  Milwaukee        45  37089             Marquette University   \n",
      "7484  Milwaukee        45  23988             Marquette University   \n",
      "\n",
      "      cost-after-aid  \n",
      "0            35248.0  \n",
      "1            35248.0  \n",
      "2            35248.0  \n",
      "3            35248.0  \n",
      "4            35248.0  \n",
      "...              ...  \n",
      "7480         32894.0  \n",
      "7481         32894.0  \n",
      "7482         32894.0  \n",
      "7483         32894.0  \n",
      "7484         32894.0  \n",
      "\n",
      "[7485 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Transforming categorial values to numerical values\n",
    "#Change this stuff to dictonaries and have it replace the states + cities with numbers\n",
    "cities = {'Ames':1, 'Amherst':2, 'Ann Arbor':3, 'Athens':4, 'Atlanta':5, 'Auburn':6, 'Austin':7, 'Baltimore':8, 'Baton Rouge':9, 'Berkeley':10, 'Bethlehem':11, 'Binghamton':12, 'Bloomington':12, 'Boston':13, 'Boulder':14, 'Buffalo':15, 'Burlington':16, 'Cambridge':17, 'Champaign':18, 'Chapel Hill':19, 'Charlottesville':20, 'Chestnut Hill':21, 'Chicago':22, 'Cincinnati':23, 'Clemson':24, 'Cleveland':25, 'College Park':26, 'College Station':27, 'Columbia':28, 'Columbus':29, 'Coral Gables':30, 'Corvallis':31, 'Dallas':32, 'Davis':33, 'Dayton':34, 'Denver':35, 'Durham':36, 'East Lansing':37 ,'Eugene':38, 'Evanston':39, 'Fairfax':40, 'Fayetteville':41, 'Fort Collins':42, 'Fort Worth':43, 'Gainesville':44, 'Golden':45, 'Hanover':46, 'Hempstead':47, 'Hoboken':48, 'Houghton':49, 'Houston':50, 'Iowa City':51, 'Irvine':52, 'Ithaca':53, 'Knoxville':54, 'La Jolla':55, 'Lawrence':56, 'Lincoln':57, 'Los Angeles':58, 'Macon':59, 'Madison':60, 'Manhattan':61, 'Medford':62, 'Milwaukee':63, 'Minneapolis':64, 'Nashville':65, 'New Haven':66, 'New Orleans':67, 'New York':68, 'Newark':69, 'Norman':70, 'Oxford':71, 'Pasadena':72, 'Philadelphia':73, 'Piscataway':74, 'Pittsburgh':75, 'Potsdam':76, 'Princeton':77, 'Providence':78, 'Provo':79, 'Pullman':80, 'Raleigh':81, 'Richardson':82, 'Riverside':83, 'Rochester':84, 'Salt Lake City':85, 'San Diego':86, 'San Francisco':87, 'Santa Barbara':88, 'Santa Cruz':89, 'Seattle':90, 'St. Louis':91, 'St. Paul':92, 'Stockton':93, 'Syracuse':94, 'Tallahassee':95, 'Tampa':96, 'Tempe':97, 'Troy':98, 'Tucson':99, 'Tulsa':100, 'Tuscaloosa':101, 'Waco':102, 'Waltham':103, 'Washington':104, 'West Lafayette':105, 'Williamsburg':106, 'Worcester':107}\n",
    "\n",
    "state_abbreviations = {'AL':1, 'AR':2, 'AZ':3, 'CA':4, 'CO':5, 'CT':6, 'DC':7, 'DE':8, 'FL':9, 'GA':10, 'IA':11, 'ID':12, 'IL':13, 'IN':14, 'KS':15, 'KY':16, 'LA':17, 'MA':18, 'MD':19, 'ME':20, 'MI':21, 'MN':22, 'MO':23, 'MS':24, 'MT':25, 'NC':26, 'ND':27, 'NE':28, 'NH':29, 'NJ':30, 'NY':31, 'OH':32, 'OK':33, 'OR':34, 'PA':35, 'RI':36, 'SC':37, 'SD':38, 'TN':39, 'TX':40, 'UT':41, 'VA':42, 'VT':43, 'WA':44, 'WI':45, 'WV':46, 'WY':47}\n",
    "\n",
    "\n",
    "data1 = data.replace(list(state_abbreviations.keys()), list(state_abbreviations.values()))\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      City  State_ab   Mean                      displayName  cost-after-aid\n",
      "0       25         1  55127  Case Western Reserve University         35248.0\n",
      "1       25         1  56385  Case Western Reserve University         35248.0\n",
      "2       25        10  44684  Case Western Reserve University         35248.0\n",
      "3       25        24  34603  Case Western Reserve University         35248.0\n",
      "4       25        24  25632  Case Western Reserve University         35248.0\n",
      "...    ...       ...    ...                              ...             ...\n",
      "7480    63        45  45808             Marquette University         32894.0\n",
      "7481    63        45  38857             Marquette University         32894.0\n",
      "7482    63        45  59171             Marquette University         32894.0\n",
      "7483    63        45  37089             Marquette University         32894.0\n",
      "7484    63        45  23988             Marquette University         32894.0\n",
      "\n",
      "[7485 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "data2 = data1.replace(list(cities.keys()), list(cities.values()))\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# X = merged_data.iloc[:,1:6].values.reshape(-1, 1)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m X \u001b[39m=\u001b[39m data2\u001b[39m.\u001b[39miloc[:,\u001b[39m1\u001b[39m:\u001b[39m6\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m----> 3\u001b[0m y \u001b[39m=\u001b[39m data2\u001b[39m.\u001b[39;49miloc[:,\u001b[39m6\u001b[39;49m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      5\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n\u001b[0;32m      6\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1096\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1594\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_getitem_tuple\u001b[39m(\u001b[39mself\u001b[39m, tup: \u001b[39mtuple\u001b[39m):\n\u001b[1;32m-> 1594\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_tuple_indexer(tup)\n\u001b[0;32m   1595\u001b[0m     \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1596\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:904\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[39mfor\u001b[39;00m i, k \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(key):\n\u001b[0;32m    903\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 904\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_key(k, i)\n\u001b[0;32m    905\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    906\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    907\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLocation based indexing can only have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    908\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_valid_types\u001b[39m}\u001b[39;00m\u001b[39m] types\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1496\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1495\u001b[0m \u001b[39melif\u001b[39;00m is_integer(key):\n\u001b[1;32m-> 1496\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_integer(key, axis)\n\u001b[0;32m   1497\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m   1498\u001b[0m     \u001b[39m# a tuple should already have been caught by this point\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m     \u001b[39m# so don't treat a tuple as a valid indexer\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[39mraise\u001b[39;00m IndexingError(\u001b[39m\"\u001b[39m\u001b[39mToo many indexers\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1589\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1587\u001b[0m len_axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1588\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1589\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "\n",
    "# X = merged_data.iloc[:,1:6].values.reshape(-1, 1)\n",
    "X = data2.iloc[:,1:6].values\n",
    "y = data2.iloc[:,6].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the LinearRegression model\n",
    "model = LinearRegression()\n",
    "\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "['Ames' 'Amherst' 'Ann Arbor' 'Athens' 'Atlanta' 'Auburn' 'Austin'\n",
      " 'Baltimore' 'Baton Rouge' 'Berkeley' 'Bethlehem' 'Binghamton'\n",
      " 'Bloomington' 'Boston' 'Boulder' 'Buffalo' 'Burlington' 'Cambridge'\n",
      " 'Champaign' 'Chapel Hill' 'Charlottesville' 'Chestnut Hill' 'Chicago'\n",
      " 'Cincinnati' 'Clemson' 'Cleveland' 'College Park' 'College Station'\n",
      " 'Columbia' 'Columbus' 'Coral Gables' 'Corvallis' 'Dallas' 'Davis'\n",
      " 'Dayton' 'Denver' 'Durham' 'East Lansing' 'Eugene' 'Evanston' 'Fairfax'\n",
      " 'Fayetteville' 'Fort Collins' 'Fort Worth' 'Gainesville' 'Golden'\n",
      " 'Hanover' 'Hempstead' 'Hoboken' 'Houghton' 'Houston' 'Iowa City' 'Irvine'\n",
      " 'Ithaca' 'Knoxville' 'La Jolla' 'Lawrence' 'Lincoln' 'Los Angeles'\n",
      " 'Macon' 'Madison' 'Manhattan' 'Medford' 'Milwaukee' 'Minneapolis'\n",
      " 'Nashville' 'New Haven' 'New Orleans' 'New York' 'Newark' 'Norman'\n",
      " 'Oxford' 'Pasadena' 'Philadelphia' 'Piscataway' 'Pittsburgh' 'Potsdam'\n",
      " 'Princeton' 'Providence' 'Provo' 'Pullman' 'Raleigh' 'Richardson'\n",
      " 'Riverside' 'Rochester' 'Salt Lake City' 'San Diego' 'San Francisco'\n",
      " 'Santa Barbara' 'Santa Cruz' 'Seattle' 'St. Louis' 'St. Paul' 'Stockton'\n",
      " 'Syracuse' 'Tallahassee' 'Tampa' 'Tempe' 'Troy' 'Tucson' 'Tulsa'\n",
      " 'Tuscaloosa' 'Waco' 'Waltham' 'Washington' 'West Lafayette'\n",
      " 'Williamsburg' 'Worcester']\n",
      "['AL' 'AR' 'AZ' 'CA' 'CO' 'CT' 'DC' 'DE' 'FL' 'GA' 'IA' 'ID' 'IL' 'IN'\n",
      " 'KS' 'KY' 'LA' 'MA' 'MD' 'ME' 'MI' 'MN' 'MO' 'MS' 'MT' 'NC' 'ND' 'NE'\n",
      " 'NH' 'NJ' 'NY' 'OH' 'OK' 'OR' 'PA' 'RI' 'SC' 'SD' 'TN' 'TX' 'UT' 'VA'\n",
      " 'VT' 'WA' 'WI' 'WV' 'WY']\n",
      "[  5000  10939  11282 ... 203870 206380 242857]\n",
      "['Ames' 'Amherst' 'Ann Arbor' 'Athens' 'Atlanta' 'Auburn' 'Austin'\n",
      " 'Baltimore' 'Baton Rouge' 'Berkeley' 'Bethlehem' 'Binghamton'\n",
      " 'Bloomington' 'Boston' 'Boulder' 'Buffalo' 'Burlington' 'Cambridge'\n",
      " 'Champaign' 'Chapel Hill' 'Charlottesville' 'Chestnut Hill' 'Chicago'\n",
      " 'Cincinnati' 'Clemson' 'Cleveland' 'College Park' 'College Station'\n",
      " 'Columbia' 'Columbus' 'Coral Gables' 'Corvallis' 'Dallas' 'Davis'\n",
      " 'Dayton' 'Denver' 'Durham' 'East Lansing' 'Eugene' 'Evanston' 'Fairfax'\n",
      " 'Fayetteville' 'Fort Collins' 'Fort Worth' 'Gainesville' 'Golden'\n",
      " 'Hanover' 'Hempstead' 'Hoboken' 'Houghton' 'Houston' 'Iowa City' 'Irvine'\n",
      " 'Ithaca' 'Knoxville' 'La Jolla' 'Lawrence' 'Lincoln' 'Los Angeles'\n",
      " 'Macon' 'Madison' 'Manhattan' 'Medford' 'Milwaukee' 'Minneapolis'\n",
      " 'Nashville' 'New Haven' 'New Orleans' 'New York' 'Newark' 'Norman'\n",
      " 'Oxford' 'Pasadena' 'Philadelphia' 'Piscataway' 'Pittsburgh' 'Potsdam'\n",
      " 'Princeton' 'Providence' 'Provo' 'Pullman' 'Raleigh' 'Richardson'\n",
      " 'Riverside' 'Rochester' 'Salt Lake City' 'San Diego' 'San Francisco'\n",
      " 'Santa Barbara' 'Santa Cruz' 'Seattle' 'St. Louis' 'St. Paul' 'Stockton'\n",
      " 'Syracuse' 'Tallahassee' 'Tampa' 'Tempe' 'Troy' 'Tucson' 'Tulsa'\n",
      " 'Tuscaloosa' 'Waco' 'Waltham' 'Washington' 'West Lafayette'\n",
      " 'Williamsburg' 'Worcester']\n",
      "['AL' 'AR' 'AZ' 'CA' 'CO' 'CT' 'DC' 'FL' 'GA' 'IA' 'IL' 'IN' 'KS' 'LA'\n",
      " 'MA' 'MD' 'MI' 'MN' 'MO' 'NC' 'NE' 'NH' 'NJ' 'NY' 'OH' 'OK' 'OR' 'PA'\n",
      " 'RI' 'SC' 'TN' 'TX' 'UT' 'VA' 'VT' 'WA' 'WI']\n",
      "['American University' 'Arizona State University--Tempe'\n",
      " 'Auburn University' 'Baylor University' 'Binghamton University--SUNY'\n",
      " 'Boston College' 'Boston University' 'Brandeis University'\n",
      " 'Brigham Young University--Provo' 'Brown University'\n",
      " 'California Institute of Technology' 'Carnegie Mellon University'\n",
      " 'Case Western Reserve University' 'Clark University'\n",
      " 'Clarkson University' 'Clemson University' 'College of William and Mary'\n",
      " 'Colorado School of Mines' 'Colorado State University'\n",
      " 'Columbia University' 'Cornell University' 'Dartmouth College'\n",
      " 'DePaul University' 'Drexel University' 'Duke University'\n",
      " 'Duquesne University' 'Emory University' 'Florida State University'\n",
      " 'George Mason University' 'George Washington University'\n",
      " 'Georgetown University' 'Georgia Institute of Technology'\n",
      " 'Harvard University' 'Hofstra University' 'Howard University'\n",
      " 'Illinois Institute of Technology' 'Indiana University--Bloomington'\n",
      " 'Iowa State University' 'Johns Hopkins University'\n",
      " 'Kansas State University' 'Lehigh University'\n",
      " 'Louisiana State University--Baton Rouge' 'Loyola University Chicago'\n",
      " 'Marquette University' 'Massachusetts Institute of Technology'\n",
      " 'Mercer University' 'Miami University--Oxford'\n",
      " 'Michigan State University' 'Michigan Technological University'\n",
      " 'New Jersey Institute of Technology' 'New York University'\n",
      " 'North Carolina State University--Raleigh' 'Northeastern University'\n",
      " 'Northwestern University' 'Ohio State University--Columbus'\n",
      " 'Oregon State University' 'Princeton University'\n",
      " 'Purdue University--West Lafayette' 'Rensselaer Polytechnic Institute'\n",
      " 'Rice University' 'Rochester Institute of Technology'\n",
      " 'Rutgers University--New Brunswick' 'Rutgers University--Newark'\n",
      " 'Saint Louis University' 'San Diego State University'\n",
      " 'Southern Methodist University' 'St. John Fisher College'\n",
      " 'Stevens Institute of Technology' 'Syracuse University'\n",
      " 'Temple University' 'Texas A&M University--College Station'\n",
      " 'Texas Christian University' 'The Catholic University of America'\n",
      " 'The New School' 'Tufts University' 'Tulane University'\n",
      " 'University at Buffalo--SUNY' 'University of Alabama'\n",
      " 'University of Arizona' 'University of Arkansas'\n",
      " 'University of California--Berkeley' 'University of California--Davis'\n",
      " 'University of California--Irvine'\n",
      " 'University of California--Los Angeles'\n",
      " 'University of California--Riverside'\n",
      " 'University of California--San Diego'\n",
      " 'University of California--Santa Barbara'\n",
      " 'University of California--Santa Cruz' 'University of Chicago'\n",
      " 'University of Cincinnati' 'University of Colorado--Boulder'\n",
      " 'University of Dayton' 'University of Denver' 'University of Florida'\n",
      " 'University of Georgia' 'University of Illinois--Chicago'\n",
      " 'University of Illinois--Urbana-Champaign' 'University of Iowa'\n",
      " 'University of Kansas' 'University of Maryland--College Park'\n",
      " 'University of Massachusetts--Amherst' 'University of Miami'\n",
      " 'University of Michigan--Ann Arbor'\n",
      " 'University of Minnesota--Twin Cities' 'University of Missouri'\n",
      " 'University of Nebraska--Lincoln' 'University of New Hampshire'\n",
      " 'University of North Carolina--Chapel Hill' 'University of Oklahoma'\n",
      " 'University of Oregon' 'University of Pennsylvania'\n",
      " 'University of Rochester' 'University of San Diego'\n",
      " 'University of San Francisco' 'University of South Carolina'\n",
      " 'University of South Florida' 'University of Southern California'\n",
      " 'University of St. Thomas' 'University of Tennessee'\n",
      " 'University of Texas--Austin' 'University of Texas--Dallas'\n",
      " 'University of Tulsa' 'University of Utah' 'University of Vermont'\n",
      " 'University of Virginia' 'University of Washington'\n",
      " 'University of Wisconsin--Madison' 'University of the Pacific'\n",
      " 'Vanderbilt University' 'Washington State University'\n",
      " 'Washington University in St. Louis' 'Worcester Polytechnic Institute'\n",
      " 'Yale University' 'Yeshiva University']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expecting 'to_replace' to be either a scalar, array-like, dict or None, got invalid type 'builtin_function_or_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19136\\509089189.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcity_numerical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'Ames'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Amherst'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Ann Arbor'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mstate_numerical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmerged_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity_numerical\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcity_numerical\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   5588\u001b[0m         \u001b[0mlimit\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5589\u001b[0m         \u001b[0mregex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pad\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ffill\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"bfill\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoDefault\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5591\u001b[0m     ) -> DataFrame | None:\n\u001b[1;32m-> 5592\u001b[1;33m         return super().replace(\n\u001b[0m\u001b[0;32m   5593\u001b[0m             \u001b[0mto_replace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5594\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5595\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   7219\u001b[0m             \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7220\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mis_re_compilable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7221\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7222\u001b[0m         ):\n\u001b[1;32m-> 7223\u001b[1;33m             raise TypeError(\n\u001b[0m\u001b[0;32m   7224\u001b[0m                 \u001b[1;34m\"Expecting 'to_replace' to be either a scalar, array-like, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7225\u001b[0m                 \u001b[1;34m\"dict or None, got invalid type \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7226\u001b[0m                 \u001b[1;34mf\"{repr(type(to_replace).__name__)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expecting 'to_replace' to be either a scalar, array-like, dict or None, got invalid type 'builtin_function_or_method'"
     ]
    }
   ],
   "source": [
    "\n",
    "# size = merged_data.shape[1]\n",
    "# print(size)\n",
    "# for index in range(0,size-1):\n",
    "#    print(np.unique(merged_data.iloc[:,index]))\n",
    "\n",
    "# city_numerical = {'Ames':1, 'Amherst':2, 'Ann Arbor':3,  }  \n",
    "# state_numerical = {}\n",
    "# merged_data.replace(city_numerical.keys,city_numerical.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "#mse = mean_squared_error(y_test, y_pred)\n",
    "#r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "#print(\"Mean Squared Error:\", mse)\n",
    "#print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# prediction of the the model \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m predicted_results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(predicted_results) \n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(y_test)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:354\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    341\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:335\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m--> 335\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    337\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, accept_sparse\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m], reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    338\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1390\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[0;32m   1386\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1387\u001b[0m     ]\n\u001b[0;32m   1389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1390\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# prediction of the the model \n",
    "predicted_results = model.predict(X_test)\n",
    "print(predicted_results) \n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#CARLOS\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# print metrics\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# # Generate the classification report\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m# print(classification_report(classification_results_categorical, y_test, zero_division=0)) \u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[39mprint\u001b[39m(mean_squared_error(y_test, predicted_results))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_results' is not defined"
     ]
    }
   ],
   "source": [
    "#CARLOS\n",
    "# print metrics\n",
    "\n",
    "# Convert continuous predictions to categorical\n",
    "# classification_results_categorical = np.round(classification_results).astype(int)\n",
    "\n",
    "# # Ensure the shape and data types match\n",
    "# classification_results_categorical = classification_results_categorical.flatten()\n",
    "# y_test = y_test.flatten()\n",
    "\n",
    "# # Generate the classification report\n",
    "# print(classification_report(classification_results_categorical, y_test, zero_division=0)) \n",
    "\n",
    "\n",
    "print(mean_squared_error(y_test, predicted_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#print confusion matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m confusion \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39;49mconfusion_matrix(X_test, classification_results)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(confusion)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfusion_matrix\u001b[39m(\n\u001b[0;32m    233\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    234\u001b[0m ):\n\u001b[0;32m    235\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \n\u001b[0;32m    237\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    319\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "#print confusion matrix\n",
    "confusion = metrics.confusion_matrix(X_test, predicted_results)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[224], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m      4\u001b[0m \u001b[39m# Compute the confusion matrix\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_true, y_pred)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Create a custom confusion matrix plot\u001b[39;00m\n\u001b[0;32m      8\u001b[0m plt\u001b[39m.\u001b[39mimshow(cm, cmap\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mcm\u001b[39m.\u001b[39mBlues)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data  # Input features\n",
    "y_true = iris.target\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Create a custom confusion matrix plot\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.xticks(ticks=np.arange(len(classes)), labels=classes)\n",
    "plt.yticks(ticks=np.arange(len(classes)), labels=classes)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
