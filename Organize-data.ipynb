{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style= \"text-align= center;\"> blah blah blah <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math as math \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some imports we'll use through the notebook, collected here for simplicity\n",
    "\n",
    "# For parsing dates and being able to compare\n",
    "import datetime\n",
    "\n",
    "# For fetching remote data\n",
    "import urllib\n",
    "\n",
    "# Pandas dataframes and operations\n",
    "import pandas as pd\n",
    "\n",
    "# Numpy matrix and array operations\n",
    "import numpy as np\n",
    "\n",
    "# Sqlite is a simplistic database\n",
    "import sqlite3\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib\n",
    "\n",
    "#HAD ISSUES INSTALLING # Crawler for multiple web pages at once\n",
    "#import scrapy\n",
    "#from scrapy.crawler import CrawlerProcess\n",
    "# Can use dataframe.swifter.apply() instead of dataframe.apply()\n",
    "# to try to parallelize the computation!\n",
    "#import swifter\n",
    "# Approximate string matching, see \n",
    "#import py_stringsimjoin as ssj\n",
    "#import py_stringmatching as sm\n",
    "# import urllib and etree for download and parsing\n",
    "#from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', delimiter=',')\n",
    "# DELIMITER WHAT SEPERATES THE DATA (;)\n",
    "\n",
    "print(type(data))\n",
    "\n",
    "#Aliyah data defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_csv('CityState.csv', delimiter=',', engine='python', encoding='latin1')\n",
    "\n",
    "#Jay's data defined \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>displayName</th>\n",
       "      <th>cost-after-aid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Princeton</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Princeton University</td>\n",
       "      <td>16793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cambridge</td>\n",
       "      <td>MA</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>16338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>University of Chicago</td>\n",
       "      <td>27767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>Yale University</td>\n",
       "      <td>18385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>21041.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city state            displayName  cost-after-aid\n",
       "0     Princeton    NJ   Princeton University         16793.0\n",
       "1     Cambridge    MA     Harvard University         16338.0\n",
       "2       Chicago    IL  University of Chicago         27767.0\n",
       "3     New Haven    CT        Yale University         18385.0\n",
       "4      New York    NY    Columbia University         21041.0\n",
       "...         ...   ...                    ...             ...\n",
       "6995        NaN   NaN                    NaN             NaN\n",
       "6996        NaN   NaN                    NaN             NaN\n",
       "6997        NaN   NaN                    NaN             NaN\n",
       "6998        NaN   NaN                    NaN             NaN\n",
       "6999        NaN   NaN                    NaN             NaN\n",
       "\n",
       "[7000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_list = ['city', 'state', 'displayName','cost-after-aid']\n",
    "row = list(range(7000))\n",
    "new_data = pd.DataFrame(data, index=row, columns=columns_list)\n",
    "new_data.head(7000)\n",
    "\n",
    "#Aliyah's data print desired columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State_ab</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chickasaw</td>\n",
       "      <td>AL</td>\n",
       "      <td>38773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Louisville</td>\n",
       "      <td>AL</td>\n",
       "      <td>37725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Columbiana</td>\n",
       "      <td>AL</td>\n",
       "      <td>54606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Satsuma</td>\n",
       "      <td>AL</td>\n",
       "      <td>63919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dauphin Island</td>\n",
       "      <td>AL</td>\n",
       "      <td>77948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>Pompano Beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>50778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>Dania Beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>69836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>Coral Springs</td>\n",
       "      <td>FL</td>\n",
       "      <td>150858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>Coral Springs</td>\n",
       "      <td>FL</td>\n",
       "      <td>119477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>Coconut Creek</td>\n",
       "      <td>FL</td>\n",
       "      <td>47168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                City State_ab    Mean\n",
       "0          Chickasaw       AL   38773\n",
       "1         Louisville       AL   37725\n",
       "2         Columbiana       AL   54606\n",
       "3            Satsuma       AL   63919\n",
       "4     Dauphin Island       AL   77948\n",
       "...              ...      ...     ...\n",
       "6995   Pompano Beach       FL   50778\n",
       "6996     Dania Beach       FL   69836\n",
       "6997   Coral Springs       FL  150858\n",
       "6998   Coral Springs       FL  119477\n",
       "6999   Coconut Creek       FL   47168\n",
       "\n",
       "[7000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_list = ['City', 'State_ab', 'Mean']\n",
    "row = list(range(7000))\n",
    "new_data = pd.DataFrame(data_2, index=row, columns=columns_list)\n",
    "new_data.head(7000)\n",
    "\n",
    "#Jay's data print desired columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 City State_ab   Mean\n",
      "0           Chickasaw       AL  38773\n",
      "1          Louisville       AL  37725\n",
      "2          Columbiana       AL  54606\n",
      "3             Satsuma       AL  63919\n",
      "4      Dauphin Island       AL  77948\n",
      "...               ...      ...    ...\n",
      "32521        Guaynabo       PR  30649\n",
      "32522          Aguada       PR  15520\n",
      "32523          Aguada       PR  41933\n",
      "32524          Aguada       PR      0\n",
      "32525       Aguadilla       PR  28049\n",
      "\n",
      "[32526 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "jay_data = data_2[['City', 'State_ab', 'Mean']]\n",
    "print(jay_data)\n",
    "#Jay's data print desired columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            city state                       displayName  cost-after-aid\n",
      "0      Princeton    NJ              Princeton University         16793.0\n",
      "1      Cambridge    MA                Harvard University         16338.0\n",
      "2        Chicago    IL             University of Chicago         27767.0\n",
      "3      New Haven    CT                   Yale University         18385.0\n",
      "4       New York    NY               Columbia University         21041.0\n",
      "..           ...   ...                               ...             ...\n",
      "306      Cypress    CA  Trident University International             NaN\n",
      "307   Cincinnati    OH    Union Institute and University             NaN\n",
      "308      Phoenix    AZ             University of Phoenix             NaN\n",
      "309  Minneapolis    MN                 Walden University             NaN\n",
      "310   New Castle    DE             Wilmington University             NaN\n",
      "\n",
      "[311 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the name and born data in exec_df.  We do this via projection.  \n",
    "# Notice also (e.g. row 24) that special characters will cause issues.\n",
    "\n",
    "\n",
    "aliyah_data = data[['city', 'state', 'displayName','cost-after-aid']]\n",
    "print(aliyah_data)\n",
    "#Aliyah's data print desired columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           city state                      displayName  cost-after-aid\n",
      "0     Princeton    NJ             Princeton University         16793.0\n",
      "1     Cambridge    MA               Harvard University         16338.0\n",
      "2       Chicago    IL            University of Chicago         27767.0\n",
      "3     New Haven    CT                  Yale University         18385.0\n",
      "4      New York    NY              Columbia University         21041.0\n",
      "..          ...   ...                              ...             ...\n",
      "145   Corvallis    OR          Oregon State University         36636.0\n",
      "146   Rochester    NY          St. John Fisher College         28750.0\n",
      "147     Chicago    IL  University of Illinois--Chicago         39033.0\n",
      "148  University    MS        University of Mississippi         27943.0\n",
      "149  Richardson    TX      University of Texas--Dallas         37028.0\n",
      "\n",
      "[143 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(aliyah_data) \n",
    "aliyah_clean = df.dropna()\n",
    "print(aliyah_clean)\n",
    "#Aliyah data dropped all NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 City State_ab   Mean\n",
      "0           Chickasaw       AL  38773\n",
      "1          Louisville       AL  37725\n",
      "2          Columbiana       AL  54606\n",
      "3             Satsuma       AL  63919\n",
      "4      Dauphin Island       AL  77948\n",
      "...               ...      ...    ...\n",
      "32521        Guaynabo       PR  30649\n",
      "32522          Aguada       PR  15520\n",
      "32523          Aguada       PR  41933\n",
      "32524          Aguada       PR      0\n",
      "32525       Aguadilla       PR  28049\n",
      "\n",
      "[32526 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(jay_data) \n",
    "df_dropped = df.dropna()\n",
    "print(df_dropped)\n",
    "#Jay data dropped all NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 City State_ab   Mean\n",
      "0           Chickasaw       AL  38773\n",
      "1          Louisville       AL  37725\n",
      "2          Columbiana       AL  54606\n",
      "3             Satsuma       AL  63919\n",
      "4      Dauphin Island       AL  77948\n",
      "...               ...      ...    ...\n",
      "32520        Adjuntas       PR  23682\n",
      "32521        Guaynabo       PR  30649\n",
      "32522          Aguada       PR  15520\n",
      "32523          Aguada       PR  41933\n",
      "32525       Aguadilla       PR  28049\n",
      "\n",
      "[32211 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "jay_clean = df_dropped[df_dropped['Mean'] != 0]\n",
    "\n",
    "print(jay_clean)\n",
    "\n",
    "#Jay's data that dropped the 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           City State_ab   Mean       city state   \n",
      "0     Cleveland       AL  55127  Cleveland    OH  \\\n",
      "1     Cleveland       AL  56385  Cleveland    OH   \n",
      "2     Cleveland       GA  44684  Cleveland    OH   \n",
      "3     Cleveland       MS  34603  Cleveland    OH   \n",
      "4     Cleveland       MS  25632  Cleveland    OH   \n",
      "...         ...      ...    ...        ...   ...   \n",
      "7480  Milwaukee       WI  45808  Milwaukee    WI   \n",
      "7481  Milwaukee       WI  38857  Milwaukee    WI   \n",
      "7482  Milwaukee       WI  59171  Milwaukee    WI   \n",
      "7483  Milwaukee       WI  37089  Milwaukee    WI   \n",
      "7484  Milwaukee       WI  23988  Milwaukee    WI   \n",
      "\n",
      "                          displayName  cost-after-aid  \n",
      "0     Case Western Reserve University         35248.0  \n",
      "1     Case Western Reserve University         35248.0  \n",
      "2     Case Western Reserve University         35248.0  \n",
      "3     Case Western Reserve University         35248.0  \n",
      "4     Case Western Reserve University         35248.0  \n",
      "...                               ...             ...  \n",
      "7480             Marquette University         32894.0  \n",
      "7481             Marquette University         32894.0  \n",
      "7482             Marquette University         32894.0  \n",
      "7483             Marquette University         32894.0  \n",
      "7484             Marquette University         32894.0  \n",
      "\n",
      "[7485 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.merge(jay_clean, aliyah_clean, left_on='City', right_on='city')\n",
    "print(merged_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City State_ab   Mean       city state   \n",
      "0  Cleveland       AL  55127  Cleveland    OH  \\\n",
      "\n",
      "                       displayName  cost-after-aid  \n",
      "0  Case Western Reserve University         35248.0  \n"
     ]
    }
   ],
   "source": [
    "print(merged_data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming categorial values to numerical values\n",
    "city_numerical = {'Ames':1, 'Amherst':2, 'Ann Arbor':3, .. }  \n",
    "state_numerical = {}\n",
    "merged_data.replace(city_numerical.keys,city_numerical.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 33598]\n",
      " [ 68465]\n",
      " [120266]\n",
      " ...\n",
      " [109775]\n",
      " [ 52434]\n",
      " [ 63019]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = merged_data.iloc[:,1:6].values.reshape(-1, 1)\n",
    "y = merged_data.iloc[:,6].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the LinearRegression model\n",
    "model = LinearRegression()\n",
    "\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "['Ames' 'Amherst' 'Ann Arbor' 'Athens' 'Atlanta' 'Auburn' 'Austin'\n",
      " 'Baltimore' 'Baton Rouge' 'Berkeley' 'Bethlehem' 'Binghamton'\n",
      " 'Bloomington' 'Boston' 'Boulder' 'Buffalo' 'Burlington' 'Cambridge'\n",
      " 'Champaign' 'Chapel Hill' 'Charlottesville' 'Chestnut Hill' 'Chicago'\n",
      " 'Cincinnati' 'Clemson' 'Cleveland' 'College Park' 'College Station'\n",
      " 'Columbia' 'Columbus' 'Coral Gables' 'Corvallis' 'Dallas' 'Davis'\n",
      " 'Dayton' 'Denver' 'Durham' 'East Lansing' 'Eugene' 'Evanston' 'Fairfax'\n",
      " 'Fayetteville' 'Fort Collins' 'Fort Worth' 'Gainesville' 'Golden'\n",
      " 'Hanover' 'Hempstead' 'Hoboken' 'Houghton' 'Houston' 'Iowa City' 'Irvine'\n",
      " 'Ithaca' 'Knoxville' 'La Jolla' 'Lawrence' 'Lincoln' 'Los Angeles'\n",
      " 'Macon' 'Madison' 'Manhattan' 'Medford' 'Milwaukee' 'Minneapolis'\n",
      " 'Nashville' 'New Haven' 'New Orleans' 'New York' 'Newark' 'Norman'\n",
      " 'Oxford' 'Pasadena' 'Philadelphia' 'Piscataway' 'Pittsburgh' 'Potsdam'\n",
      " 'Princeton' 'Providence' 'Provo' 'Pullman' 'Raleigh' 'Richardson'\n",
      " 'Riverside' 'Rochester' 'Salt Lake City' 'San Diego' 'San Francisco'\n",
      " 'Santa Barbara' 'Santa Cruz' 'Seattle' 'St. Louis' 'St. Paul' 'Stockton'\n",
      " 'Syracuse' 'Tallahassee' 'Tampa' 'Tempe' 'Troy' 'Tucson' 'Tulsa'\n",
      " 'Tuscaloosa' 'Waco' 'Waltham' 'Washington' 'West Lafayette'\n",
      " 'Williamsburg' 'Worcester']\n",
      "['AL' 'AR' 'AZ' 'CA' 'CO' 'CT' 'DC' 'DE' 'FL' 'GA' 'IA' 'ID' 'IL' 'IN'\n",
      " 'KS' 'KY' 'LA' 'MA' 'MD' 'ME' 'MI' 'MN' 'MO' 'MS' 'MT' 'NC' 'ND' 'NE'\n",
      " 'NH' 'NJ' 'NY' 'OH' 'OK' 'OR' 'PA' 'RI' 'SC' 'SD' 'TN' 'TX' 'UT' 'VA'\n",
      " 'VT' 'WA' 'WI' 'WV' 'WY']\n",
      "[  5000  10939  11282 ... 203870 206380 242857]\n",
      "['Ames' 'Amherst' 'Ann Arbor' 'Athens' 'Atlanta' 'Auburn' 'Austin'\n",
      " 'Baltimore' 'Baton Rouge' 'Berkeley' 'Bethlehem' 'Binghamton'\n",
      " 'Bloomington' 'Boston' 'Boulder' 'Buffalo' 'Burlington' 'Cambridge'\n",
      " 'Champaign' 'Chapel Hill' 'Charlottesville' 'Chestnut Hill' 'Chicago'\n",
      " 'Cincinnati' 'Clemson' 'Cleveland' 'College Park' 'College Station'\n",
      " 'Columbia' 'Columbus' 'Coral Gables' 'Corvallis' 'Dallas' 'Davis'\n",
      " 'Dayton' 'Denver' 'Durham' 'East Lansing' 'Eugene' 'Evanston' 'Fairfax'\n",
      " 'Fayetteville' 'Fort Collins' 'Fort Worth' 'Gainesville' 'Golden'\n",
      " 'Hanover' 'Hempstead' 'Hoboken' 'Houghton' 'Houston' 'Iowa City' 'Irvine'\n",
      " 'Ithaca' 'Knoxville' 'La Jolla' 'Lawrence' 'Lincoln' 'Los Angeles'\n",
      " 'Macon' 'Madison' 'Manhattan' 'Medford' 'Milwaukee' 'Minneapolis'\n",
      " 'Nashville' 'New Haven' 'New Orleans' 'New York' 'Newark' 'Norman'\n",
      " 'Oxford' 'Pasadena' 'Philadelphia' 'Piscataway' 'Pittsburgh' 'Potsdam'\n",
      " 'Princeton' 'Providence' 'Provo' 'Pullman' 'Raleigh' 'Richardson'\n",
      " 'Riverside' 'Rochester' 'Salt Lake City' 'San Diego' 'San Francisco'\n",
      " 'Santa Barbara' 'Santa Cruz' 'Seattle' 'St. Louis' 'St. Paul' 'Stockton'\n",
      " 'Syracuse' 'Tallahassee' 'Tampa' 'Tempe' 'Troy' 'Tucson' 'Tulsa'\n",
      " 'Tuscaloosa' 'Waco' 'Waltham' 'Washington' 'West Lafayette'\n",
      " 'Williamsburg' 'Worcester']\n",
      "['AL' 'AR' 'AZ' 'CA' 'CO' 'CT' 'DC' 'FL' 'GA' 'IA' 'IL' 'IN' 'KS' 'LA'\n",
      " 'MA' 'MD' 'MI' 'MN' 'MO' 'NC' 'NE' 'NH' 'NJ' 'NY' 'OH' 'OK' 'OR' 'PA'\n",
      " 'RI' 'SC' 'TN' 'TX' 'UT' 'VA' 'VT' 'WA' 'WI']\n",
      "['American University' 'Arizona State University--Tempe'\n",
      " 'Auburn University' 'Baylor University' 'Binghamton University--SUNY'\n",
      " 'Boston College' 'Boston University' 'Brandeis University'\n",
      " 'Brigham Young University--Provo' 'Brown University'\n",
      " 'California Institute of Technology' 'Carnegie Mellon University'\n",
      " 'Case Western Reserve University' 'Clark University'\n",
      " 'Clarkson University' 'Clemson University' 'College of William and Mary'\n",
      " 'Colorado School of Mines' 'Colorado State University'\n",
      " 'Columbia University' 'Cornell University' 'Dartmouth College'\n",
      " 'DePaul University' 'Drexel University' 'Duke University'\n",
      " 'Duquesne University' 'Emory University' 'Florida State University'\n",
      " 'George Mason University' 'George Washington University'\n",
      " 'Georgetown University' 'Georgia Institute of Technology'\n",
      " 'Harvard University' 'Hofstra University' 'Howard University'\n",
      " 'Illinois Institute of Technology' 'Indiana University--Bloomington'\n",
      " 'Iowa State University' 'Johns Hopkins University'\n",
      " 'Kansas State University' 'Lehigh University'\n",
      " 'Louisiana State University--Baton Rouge' 'Loyola University Chicago'\n",
      " 'Marquette University' 'Massachusetts Institute of Technology'\n",
      " 'Mercer University' 'Miami University--Oxford'\n",
      " 'Michigan State University' 'Michigan Technological University'\n",
      " 'New Jersey Institute of Technology' 'New York University'\n",
      " 'North Carolina State University--Raleigh' 'Northeastern University'\n",
      " 'Northwestern University' 'Ohio State University--Columbus'\n",
      " 'Oregon State University' 'Princeton University'\n",
      " 'Purdue University--West Lafayette' 'Rensselaer Polytechnic Institute'\n",
      " 'Rice University' 'Rochester Institute of Technology'\n",
      " 'Rutgers University--New Brunswick' 'Rutgers University--Newark'\n",
      " 'Saint Louis University' 'San Diego State University'\n",
      " 'Southern Methodist University' 'St. John Fisher College'\n",
      " 'Stevens Institute of Technology' 'Syracuse University'\n",
      " 'Temple University' 'Texas A&M University--College Station'\n",
      " 'Texas Christian University' 'The Catholic University of America'\n",
      " 'The New School' 'Tufts University' 'Tulane University'\n",
      " 'University at Buffalo--SUNY' 'University of Alabama'\n",
      " 'University of Arizona' 'University of Arkansas'\n",
      " 'University of California--Berkeley' 'University of California--Davis'\n",
      " 'University of California--Irvine'\n",
      " 'University of California--Los Angeles'\n",
      " 'University of California--Riverside'\n",
      " 'University of California--San Diego'\n",
      " 'University of California--Santa Barbara'\n",
      " 'University of California--Santa Cruz' 'University of Chicago'\n",
      " 'University of Cincinnati' 'University of Colorado--Boulder'\n",
      " 'University of Dayton' 'University of Denver' 'University of Florida'\n",
      " 'University of Georgia' 'University of Illinois--Chicago'\n",
      " 'University of Illinois--Urbana-Champaign' 'University of Iowa'\n",
      " 'University of Kansas' 'University of Maryland--College Park'\n",
      " 'University of Massachusetts--Amherst' 'University of Miami'\n",
      " 'University of Michigan--Ann Arbor'\n",
      " 'University of Minnesota--Twin Cities' 'University of Missouri'\n",
      " 'University of Nebraska--Lincoln' 'University of New Hampshire'\n",
      " 'University of North Carolina--Chapel Hill' 'University of Oklahoma'\n",
      " 'University of Oregon' 'University of Pennsylvania'\n",
      " 'University of Rochester' 'University of San Diego'\n",
      " 'University of San Francisco' 'University of South Carolina'\n",
      " 'University of South Florida' 'University of Southern California'\n",
      " 'University of St. Thomas' 'University of Tennessee'\n",
      " 'University of Texas--Austin' 'University of Texas--Dallas'\n",
      " 'University of Tulsa' 'University of Utah' 'University of Vermont'\n",
      " 'University of Virginia' 'University of Washington'\n",
      " 'University of Wisconsin--Madison' 'University of the Pacific'\n",
      " 'Vanderbilt University' 'Washington State University'\n",
      " 'Washington University in St. Louis' 'Worcester Polytechnic Institute'\n",
      " 'Yale University' 'Yeshiva University']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "size = merged_data.shape[1]\n",
    "print(size)\n",
    "for index in range(0,size-1):\n",
    "   print(np.unique(merged_data.iloc[:,index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "#mse = mean_squared_error(y_test, y_pred)\n",
    "#r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "#print(\"Mean Squared Error:\", mse)\n",
    "#print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34120.93675431 34501.16495914 35066.06016776 ... 34951.65473865\n",
      " 34326.34526282 34441.77577156]\n",
      "[27962. 49957. 27767. ... 39033. 21041. 36861.]\n"
     ]
    }
   ],
   "source": [
    "# prediction of the the model \n",
    "predicted_results = model.predict(X_test)\n",
    "print(predicted_results) \n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52544429.24464864\n"
     ]
    }
   ],
   "source": [
    "#CARLOS\n",
    "# print metrics\n",
    "\n",
    "# Convert continuous predictions to categorical\n",
    "# classification_results_categorical = np.round(classification_results).astype(int)\n",
    "\n",
    "# # Ensure the shape and data types match\n",
    "# classification_results_categorical = classification_results_categorical.flatten()\n",
    "# y_test = y_test.flatten()\n",
    "\n",
    "# # Generate the classification report\n",
    "# print(classification_report(classification_results_categorical, y_test, zero_division=0)) \n",
    "\n",
    "\n",
    "print(mean_squared_error(y_test, predicted_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#print confusion matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m confusion \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39;49mconfusion_matrix(X_test, classification_results)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(confusion)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfusion_matrix\u001b[39m(\n\u001b[0;32m    233\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    234\u001b[0m ):\n\u001b[0;32m    235\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \n\u001b[0;32m    237\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    319\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "#print confusion matrix\n",
    "confusion = metrics.confusion_matrix(X_test, classification_results)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[224], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m      4\u001b[0m \u001b[39m# Compute the confusion matrix\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_true, y_pred)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Create a custom confusion matrix plot\u001b[39;00m\n\u001b[0;32m      8\u001b[0m plt\u001b[39m.\u001b[39mimshow(cm, cmap\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mcm\u001b[39m.\u001b[39mBlues)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data  # Input features\n",
    "y_true = iris.target\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Create a custom confusion matrix plot\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.xticks(ticks=np.arange(len(classes)), labels=classes)\n",
    "plt.yticks(ticks=np.arange(len(classes)), labels=classes)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
